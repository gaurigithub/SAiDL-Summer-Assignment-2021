1. Train an image classification model of your choice (eg. CNNs such as ResNets) on the labelled part of the dataset in a supervised way and report results on the test set.
(PyTorch 1.3 with CUDA on google colab)
HYPERPARAMETERS:
Batch size: 256
Model architecture: ResNet 9
A total of: 8 convolutional layer + 1 linear layer        (CONV NETS)
     With dropout → 0.2


Also including techniques such as 


> channel wise data normalization on both training and testing data
> Random data augmentation on the training data to counter overfitting
        >Random horizontal flip
        >Random vertical flip
        >Color Jitter : Brightness = 0.1
Contrast =0.1
saturation= 0.1
Hue = 0.1
Epochs : 40
Max Learning rate: 0.01 
Weight Decay: 1e-4
Optimiser function: Adam


Train_time:
CPU times: user 17min 45s, sys: 29.9 s, total: 18min 15s
Wall time: 24min 54s
                Validation accuracy: 79.14%
                  




2. semi-supervised training:
Hyperparameters:
        Model: pseudo-labeling
        Batch size reduced to 128 
Epochs: 100


Validation accuracy: still-training 
        
T1 = 40
T2 = 280
af = 3
     step < T1    alpha_weigh 0.0
     step > T2    alpha_weigh= 3
     Else                  alpha_weigh= ((step-T1) / (T2-T1))*af








When you would expect semi-supervised learning approaches to fail. What can you do to avoid this? 


> If unlabeled data comes from a significantly different distribution than the labeled dataset then one should not use self-supervised learning but try domain adaptation instead.
> the number of unlabeled data must be atleast as much as labeled or several orders of magnitude more. Because otherwise we won’t have enough incentive, time, and resources.




Apart from achieving a high test set accuracy, what other metrics do you think are important while comparing and contrasting different learning approaches? (think sample efficiency, training time)


> Supervised and semi-supervised, since semi-supervised takes much longer and several epochs to train so mostly incase of performance-critical applications where a 5–10%+ relative reduction in error rates is significant and where unlabeled data is available, ssl proves to be impactful other than that if less unlabeled data then ssl reciprocates less.